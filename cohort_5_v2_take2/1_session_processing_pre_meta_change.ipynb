{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import session_processing_helper_c5v2 as helper\n",
    "import utils_c5v2 as utils\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rebekahzhang/data/behavior_data/20240123-20240415/exp2/cohort_5\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/rebekahzhang/data/behavior_data'\n",
    "period = '20240123-20240415'\n",
    "exp = \"exp2\"\n",
    "cohort = \"cohort_5\"\n",
    "data_folder = os.path.join(data_dir, period, exp, cohort)\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check session folders have both meta and events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_session_files(data_folder):\n",
    "    files_check = []\n",
    "    for entry in os.scandir(data_folder):\n",
    "        if entry.is_dir():\n",
    "            dir = entry.name\n",
    "            session_path = os.path.join(data_folder, dir)\n",
    "            events_found = False\n",
    "            meta_found = False\n",
    "            events_empty = True\n",
    "            meta_empty = True\n",
    "            \n",
    "            required_files = [f for f in os.scandir(session_path) if f.is_file() and not f.name.startswith('.')]\n",
    "            \n",
    "            for file in required_files:\n",
    "                if file.name.startswith(\"events_\"):\n",
    "                    events_found = True\n",
    "                    if file.stat().st_size > 0:\n",
    "                        events_empty = False\n",
    "                elif file.name.startswith(\"meta_\"):\n",
    "                    meta_found = True\n",
    "                    if file.stat().st_size > 0:\n",
    "                        meta_empty = False\n",
    "            \n",
    "            files_check.append({\n",
    "                'dir': dir,\n",
    "                'events': events_found,\n",
    "                'meta': meta_found,\n",
    "                'events_empty': events_empty if events_found else None,\n",
    "                'meta_empty': meta_empty if meta_found else None\n",
    "            })\n",
    "\n",
    "    files_check_df = pd.DataFrame(files_check).sort_values(\"dir\")\n",
    "    missing_meta = files_check_df[files_check_df.meta==False]\n",
    "    missing_events = files_check_df[files_check_df.events==False]\n",
    "    empty_meta = files_check_df[(files_check_df.meta==True) & (files_check_df.meta_empty==True)]\n",
    "    empty_events = files_check_df[(files_check_df.events==True) & (files_check_df.events_empty==True)]\n",
    "    \n",
    "    return missing_meta, missing_events, empty_meta, empty_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All sessions have non-empty meta and events files.\n"
     ]
    }
   ],
   "source": [
    "missing_events, missing_meta, empty_meta, empty_events = helper.check_session_files(data_folder)\n",
    "if not (missing_meta.empty and missing_events.empty and empty_meta.empty and empty_events.empty):\n",
    "    print(\"\\nFile check results:\")\n",
    "    if not missing_meta.empty:\n",
    "        print(\"\\nSessions missing meta files:\")\n",
    "        display(missing_meta)\n",
    "    if not missing_events.empty:\n",
    "        print(\"\\nSessions missing events files:\")\n",
    "        display(missing_events)\n",
    "    if not empty_meta.empty:\n",
    "        print(\"\\nSessions with empty meta files:\")\n",
    "        display(empty_meta)\n",
    "    if not empty_events.empty:\n",
    "        print(\"\\nSessions with empty events files:\")\n",
    "        display(empty_events)\n",
    "else:\n",
    "    print(\"\\nAll sessions have non-empty meta and events files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to delete\n"
     ]
    }
   ],
   "source": [
    "utils.delete_folders(missing_meta.dir.tolist(), data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to delete\n"
     ]
    }
   ],
   "source": [
    "utils.delete_folders(missing_events.dir.tolist(), data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to delete\n"
     ]
    }
   ],
   "source": [
    "utils.delete_folders(empty_meta.dir.tolist(), data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to delete\n"
     ]
    }
   ],
   "source": [
    "utils.delete_folders(empty_events.dir.tolist(), data_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save sessions log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate session log using meta data from each session and add columns of basic info to each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_sessions_all(sessions_all):\n",
    "    sessions_all['dir'] = sessions_all['date']+ '_' + sessions_all['time'] + '_' + sessions_all['mouse']\n",
    "    sessions_all = sessions_all.sort_values('dir')\n",
    "    sessions_all[['exp', 'group']] = sessions_all['exp'].str.extract(r'exp(\\d)_(short|long)')\n",
    "    sessions_all['group'] = sessions_all['group'].map({'short': 's', 'long': 'l'})\n",
    "    return sessions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sessions_all(data_folder):\n",
    "    \"\"\"Generates a DataFrame using session metadata from JSON files.\"\"\"\n",
    "\n",
    "    data = []\n",
    "    for root, _, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.startswith(\"meta_\") and file.endswith(\".json\"):\n",
    "                path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(path) as f:\n",
    "                        session_data = json.load(f)\n",
    "                        data.append(session_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    sessions_all = pd.DataFrame(data)\n",
    "    sessions_all = modify_sessions_all(sessions_all)\n",
    "    return sessions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sessions_training(sessions_all):\n",
    "    sessions_training = sessions_all.loc[sessions_all.training == 'regular'].reset_index()\n",
    "    sessions_training = sessions_training.groupby('mouse', group_keys=False).apply(helper.assign_session_numbers)\n",
    "    return sessions_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session_logs(data_folder, save_logs=True):\n",
    "    sessions_all = generate_sessions_all(data_folder)\n",
    "    sessions_training = generate_sessions_training(sessions_all)\n",
    "    if save_logs:\n",
    "        utils.save_as_csv(df=sessions_all, folder=data_folder, filename='sessions_all.csv')\n",
    "        utils.save_as_csv(df=sessions_training, folder=data_folder, filename='sessions_training.csv')\n",
    "    print(f\"{len(sessions_training)} sessions in total\")\n",
    "    return sessions_all, sessions_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-run after every quality control steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 sessions in total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>exp</th>\n",
       "      <th>training</th>\n",
       "      <th>rig</th>\n",
       "      <th>pump_ul_per_turn</th>\n",
       "      <th>total_trial</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>avg_tw</th>\n",
       "      <th>dir</th>\n",
       "      <th>group</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>26</td>\n",
       "      <td>RZ034</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>10-22-23</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>505</td>\n",
       "      <td>700</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2024-04-12_10-22-23_RZ034</td>\n",
       "      <td>s</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>RZ036</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>10-23-31</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>429</td>\n",
       "      <td>700</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2024-04-12_10-23-31_RZ036</td>\n",
       "      <td>s</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>231</td>\n",
       "      <td>RZ037</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>11-09-19</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>310</td>\n",
       "      <td>700</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2024-04-12_11-09-19_RZ037</td>\n",
       "      <td>l</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>176</td>\n",
       "      <td>RZ038</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>11-14-07</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>156</td>\n",
       "      <td>385</td>\n",
       "      <td>8.72</td>\n",
       "      <td>2024-04-12_11-14-07_RZ038</td>\n",
       "      <td>l</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>305</td>\n",
       "      <td>RZ039</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>12-19-19</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>264</td>\n",
       "      <td>700</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2024-04-12_12-19-19_RZ039</td>\n",
       "      <td>l</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  mouse        date      time exp training   rig  pump_ul_per_turn  \\\n",
       "276     26  RZ034  2024-04-12  10-22-23   2  regular  rig2            0.0686   \n",
       "277      0  RZ036  2024-04-12  10-23-31   2  regular  rig3            0.0659   \n",
       "278    231  RZ037  2024-04-12  11-09-19   2  regular  rig3            0.0659   \n",
       "279    176  RZ038  2024-04-12  11-14-07   2  regular  rig2            0.0686   \n",
       "280    305  RZ039  2024-04-12  12-19-19   2  regular  rig2            0.0686   \n",
       "\n",
       "     total_trial  total_reward  avg_tw                        dir group  \\\n",
       "276          505           700    1.18  2024-04-12_10-22-23_RZ034     s   \n",
       "277          429           700    1.47  2024-04-12_10-23-31_RZ036     s   \n",
       "278          310           700    4.74  2024-04-12_11-09-19_RZ037     l   \n",
       "279          156           385    8.72  2024-04-12_11-14-07_RZ038     l   \n",
       "280          264           700    3.75  2024-04-12_12-19-19_RZ039     l   \n",
       "\n",
       "     session  \n",
       "276       55  \n",
       "277       56  \n",
       "278       55  \n",
       "279       55  \n",
       "280       55  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_all, sessions_training = generate_session_logs(data_folder)\n",
    "sessions_training.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unwanted sessions\n",
    "doesn't need to run when data folder is cleaned \n",
    "<br>\n",
    "sessions_all needs to be regenerated after every cleaning step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove test sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to delete\n"
     ]
    }
   ],
   "source": [
    "sessions_test = sessions_all.loc[sessions_all.mouse=='test']\n",
    "utils.remove_sessions(sessions_test, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove crashed sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all sessions are perfect! woohoo!\n"
     ]
    }
   ],
   "source": [
    "sessions_crashed = pd.DataFrame(columns=sessions_training.columns)\n",
    "problematic_sessions = pd.DataFrame(columns=sessions_training.columns)\n",
    "\n",
    "for _, session_info in sessions_training.iterrows():\n",
    "    try:\n",
    "        events_path = utils.generate_events_path(data_folder, session_info)\n",
    "        events = pd.read_csv(events_path, low_memory=False)\n",
    "        session_end = events.loc[(events.key=='session') & (events.value==0)]\n",
    "\n",
    "        if not len(session_end)==1:\n",
    "            sessions_crashed = pd.concat([sessions_crashed, session_info.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    except:\n",
    "        problematic_sessions = pd.concat([problematic_sessions, session_info.to_frame().T], ignore_index=True)\n",
    "\n",
    "if len(problematic_sessions) > 0:\n",
    "    print(\"cannot open: \")\n",
    "    display(problematic_sessions)\n",
    "\n",
    "if len(sessions_crashed) > 0:\n",
    "    print(\"crashed sessions: \")\n",
    "    display(sessions_crashed)\n",
    "else:\n",
    "    print(\"all sessions are perfect! woohoo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to delete\n"
     ]
    }
   ],
   "source": [
    "utils.remove_sessions(sessions_crashed, data_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for short sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no short sessions to be checked!\n"
     ]
    }
   ],
   "source": [
    "short_threshold = 20\n",
    "sessions_short = sessions_all[(sessions_all['total_trial'] < short_threshold) | sessions_all['total_trial'].isna()]\n",
    "if len(sessions_short)>0:\n",
    "    display(sessions_short)\n",
    "else: \n",
    "    print('no short sessions to be checked!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove short sessions if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to delete\n"
     ]
    }
   ],
   "source": [
    "utils.remove_sessions(sessions_short, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = utils.load_data(os.path.join(data_folder, 'sessions_training.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "needs to align trial number, add trial time, before trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_trial_num(events):\n",
    "    max_trial_num = events['session_trial_num'].max()\n",
    "    last_trial = events.loc[events['session_trial_num'] == max_trial_num]\n",
    "    session_end = last_trial.loc[(last_trial['key'] == 'session') & (last_trial['value'] == 0)]\n",
    "    last_trial_end = last_trial.loc[(last_trial['key'] == 'trial') & (last_trial['value'] == 0)]\n",
    "    if len(session_end) > 0 and len(last_trial_end) > 0:\n",
    "        return max_trial_num\n",
    "    else:\n",
    "        return max_trial_num - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process raw session data\n",
    "def get_trial_basics(trial):\n",
    "    \"\"\"gets the df of a trial, extracts 5 things, and outputs as a dictionary\"\"\"\n",
    "    trial_start = trial.loc[(trial['key'] == 'trial') & (trial['value'] == 1)].iloc[0]\n",
    "    trial_end = trial.loc[(trial['key'] == 'trial') & (trial['value'] == 0)].iloc[0]\n",
    "\n",
    "    trial_basics = {'session_trial_num': trial_start['session_trial_num'],\n",
    "                    'block_trial_num': trial_start['block_trial_num'],\n",
    "                    'block_num': trial_start['block_num'],\n",
    "                    'start_time': trial_start['session_time'],\n",
    "                    'end_time': trial_end['session_time']}\n",
    "    return trial_basics\n",
    "\n",
    "def generate_trials(events, max_trial_num):\n",
    "    trial_info_list = []\n",
    "    for t in range(int(max_trial_num)+1):\n",
    "        trial = events.loc[events['session_trial_num'] == t]\n",
    "        trial_basics = get_trial_basics(trial)\n",
    "        trial_info_list.append(trial_basics)\n",
    "    trials = pd.DataFrame(trial_info_list)\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all sessions are perfect! woohoo!\n"
     ]
    }
   ],
   "source": [
    "problematic_sessions = pd.DataFrame(columns=sessions_training.columns)\n",
    "\n",
    "for _, session_info in sessions_training.iterrows():\n",
    "    try:\n",
    "        events_processed_path = utils.generate_events_processed_path(data_folder, session_info)\n",
    "        if os.path.isfile(events_processed_path):\n",
    "            continue\n",
    "        events = pd.read_csv(utils.generate_events_path(data_folder, session_info), low_memory=False)\n",
    "        max_trial_num = get_max_trial_num(events)\n",
    "\n",
    "        trials = generate_trials(events, max_trial_num)\n",
    "        events = helper.align_trial_number(events, trials)\n",
    "        events = events.loc[events['session_trial_num'].between(0, max_trial_num)]\n",
    "\n",
    "        events = events.groupby('session_trial_num', group_keys=False).apply(helper.align_trial_states)\n",
    "        # add trial_time\n",
    "        events_processed = events.groupby('session_trial_num', group_keys=False).apply(helper.add_trial_time)\n",
    "        events_processed.to_csv(events_processed_path)\n",
    "    except:\n",
    "        problematic_sessions = pd.concat([problematic_sessions, session_info.to_frame().T], ignore_index=True)\n",
    "        \n",
    "if len(problematic_sessions) > 0:\n",
    "    display(problematic_sessions)\n",
    "else:\n",
    "    print(\"all sessions are perfect! woohoo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set curation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated rounds dict cuz we no longer run more than 1 session per day\n",
    "mouse_list = utils.generate_mouse_list(sessions_all)\n",
    "sessions_by_date = sessions_training.groupby('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with missing sessions\n",
    "this is not the proper way to deal with this. should have it populated with mean and variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 2024-03-25, RZ034 has missing sessions\n",
      "on 2024-04-08, RZ037 has missing sessions\n",
      "on 2024-04-08, RZ038 has missing sessions\n",
      "on 2024-04-08, RZ039 has missing sessions\n"
     ]
    }
   ],
   "source": [
    "no_missing_sessions = True\n",
    "for date, data in sessions_by_date:\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        if len(mouse_by_date) < 1:\n",
    "            no_missing_sessions = False\n",
    "            print(f\"on {date}, {mouse} has missing sessions\")\n",
    "if no_missing_sessions:\n",
    "    print(\"no missing sessions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>exp</th>\n",
       "      <th>training</th>\n",
       "      <th>rig</th>\n",
       "      <th>pump_ul_per_turn</th>\n",
       "      <th>total_trial</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>avg_tw</th>\n",
       "      <th>dir</th>\n",
       "      <th>group</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>191</td>\n",
       "      <td>RZ036</td>\n",
       "      <td>2024-03-25</td>\n",
       "      <td>12-18-30</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>0.066</td>\n",
       "      <td>265</td>\n",
       "      <td>700</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2024-03-25_12-18-30_RZ036</td>\n",
       "      <td>s</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>226</td>\n",
       "      <td>RZ037</td>\n",
       "      <td>2024-03-25</td>\n",
       "      <td>13-33-12</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>0.067</td>\n",
       "      <td>347</td>\n",
       "      <td>700</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2024-03-25_13-33-12_RZ037</td>\n",
       "      <td>l</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>78</td>\n",
       "      <td>RZ038</td>\n",
       "      <td>2024-03-25</td>\n",
       "      <td>13-34-24</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>0.066</td>\n",
       "      <td>95</td>\n",
       "      <td>265</td>\n",
       "      <td>6.08</td>\n",
       "      <td>2024-03-25_13-34-24_RZ038</td>\n",
       "      <td>l</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>162</td>\n",
       "      <td>RZ039</td>\n",
       "      <td>2024-03-25</td>\n",
       "      <td>14-07-25</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>0.066</td>\n",
       "      <td>299</td>\n",
       "      <td>700</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2024-03-25_14-07-25_RZ039</td>\n",
       "      <td>l</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  mouse        date      time  exp training   rig  pump_ul_per_turn  \\\n",
       "210    191  RZ036  2024-03-25  12-18-30    2  regular  rig3             0.066   \n",
       "211    226  RZ037  2024-03-25  13-33-12    2  regular  rig2             0.067   \n",
       "212     78  RZ038  2024-03-25  13-34-24    2  regular  rig3             0.066   \n",
       "213    162  RZ039  2024-03-25  14-07-25    2  regular  rig3             0.066   \n",
       "\n",
       "     total_trial  total_reward  avg_tw                        dir group  \\\n",
       "210          265           700    4.03  2024-03-25_12-18-30_RZ036     s   \n",
       "211          347           700    2.47  2024-03-25_13-33-12_RZ037     l   \n",
       "212           95           265    6.08  2024-03-25_13-34-24_RZ038     l   \n",
       "213          299           700    3.89  2024-03-25_14-07-25_RZ039     l   \n",
       "\n",
       "     session  \n",
       "210       42  \n",
       "211       42  \n",
       "212       42  \n",
       "213       42  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_by_date.get_group('2024-03-25').sort_values('mouse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duplicate if you are sussed out of having to redo this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort_5 backed up\n"
     ]
    }
   ],
   "source": [
    "utils.backup(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with multiple sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to stitch!\n"
     ]
    }
   ],
   "source": [
    "days_to_stitch = []\n",
    "mice_to_stitch = []\n",
    "for date, data in sessions_by_date:\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        if len(mouse_by_date) > 1:\n",
    "            days_to_stitch.append(date)\n",
    "            mice_to_stitch.append(mouse)\n",
    "            print(f\"on {date}, {mouse} has {len(mouse_by_date)} sessions\")\n",
    "if not days_to_stitch:\n",
    "    print(\"no sessions to stitch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_basics(session_df):\n",
    "    num_trials = session_df.session_trial_num.max() \n",
    "    last_trial = session_df.loc[session_df['session_trial_num'] == num_trials]\n",
    "\n",
    "    num_blocks = last_trial.loc[(last_trial['key'] == 'trial') & (last_trial['value'] == 1), 'block_num'].iloc[0] + 1\n",
    "    total_reward = round(session_df.reward_size.sum(), 2)\n",
    "    total_time = round((session_df.session_time.max() - session_df.session_time.min()), 2)\n",
    "    session_basics = {'num_blocks': num_blocks,\n",
    "                      'num_trials': num_trials + 1,\n",
    "                      'rewards': total_reward,\n",
    "                      'session_time': total_time}\n",
    "    return session_basics  \n",
    "\n",
    "def assign_session_numbers(group):\n",
    "    group.sort_values(by=['mouse', 'dir', 'date'], inplace=True)\n",
    "    group['session'] = list(range(len(group)))\n",
    "    return group\n",
    "\n",
    "# Stitch sessions from the same mouse on the same day\n",
    "def stitch_sessions(session_1, session_2):\n",
    "    session_1_basics = get_session_basics(session_1)\n",
    "    time_offset = session_1_basics['session_time']\n",
    "    block_offset = session_1_basics['num_blocks']\n",
    "    trial_offset = session_1_basics['num_trials']\n",
    "    \n",
    "    session_2.session_time = session_2.session_time + time_offset\n",
    "    session_2.block_num = session_2.block_num + block_offset\n",
    "    session_2.session_trial_num= session_2.session_trial_num + trial_offset\n",
    "\n",
    "    stitched_session = pd.concat([session_1, session_2])\n",
    "    return stitched_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sessions to stitch!\n"
     ]
    }
   ],
   "source": [
    "# run it if session stitching is needed, nothing would happen otherwise\n",
    "# has to run more than once if there are more than 2 sessions. fix it for the next round pls\n",
    "if not days_to_stitch:\n",
    "    print(\"no sessions to stitch!\")\n",
    "else:\n",
    "    for d, m in zip(days_to_stitch, mice_to_stitch):\n",
    "        day = sessions_by_date.get_group(d)\n",
    "        sessions_to_stitch = day[day['mouse'] == m]\n",
    "\n",
    "        session_1_dir = utils.generate_events_processed_path(data_folder, sessions_to_stitch.iloc[0])\n",
    "        session_2_dir = utils.generate_events_processed_path(data_folder, sessions_to_stitch.iloc[1])\n",
    "\n",
    "        if os.path.exists(session_1_dir) and os.path.exists(session_2_dir):\n",
    "            session_1 = pd.read_csv(session_1_dir)\n",
    "            session_2 = pd.read_csv(session_2_dir)\n",
    "            stitched_session = stitch_sessions(session_1, session_2) \n",
    "            #should change to stitch events. stitch sessions should be deleted. to follow nomanclature, all session should be renamed to events!!\n",
    "\n",
    "            stitched_session.to_csv(session_1_dir, index=False)\n",
    "            shutil.rmtree(os.path.join(data_folder, sessions_to_stitch.iloc[1].dir))\n",
    "            print(f\"{d} {m} session 2 deleted\")\n",
    "        else:\n",
    "            print(\"one of the sessions do not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 sessions in total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>exp</th>\n",
       "      <th>training</th>\n",
       "      <th>rig</th>\n",
       "      <th>pump_ul_per_turn</th>\n",
       "      <th>total_trial</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>avg_tw</th>\n",
       "      <th>dir</th>\n",
       "      <th>group</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>26</td>\n",
       "      <td>RZ034</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>10-22-23</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>505</td>\n",
       "      <td>700</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2024-04-12_10-22-23_RZ034</td>\n",
       "      <td>s</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>RZ036</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>10-23-31</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>429</td>\n",
       "      <td>700</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2024-04-12_10-23-31_RZ036</td>\n",
       "      <td>s</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>231</td>\n",
       "      <td>RZ037</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>11-09-19</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>310</td>\n",
       "      <td>700</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2024-04-12_11-09-19_RZ037</td>\n",
       "      <td>l</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>176</td>\n",
       "      <td>RZ038</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>11-14-07</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>156</td>\n",
       "      <td>385</td>\n",
       "      <td>8.72</td>\n",
       "      <td>2024-04-12_11-14-07_RZ038</td>\n",
       "      <td>l</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>305</td>\n",
       "      <td>RZ039</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>12-19-19</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>264</td>\n",
       "      <td>700</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2024-04-12_12-19-19_RZ039</td>\n",
       "      <td>l</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  mouse        date      time exp training   rig  pump_ul_per_turn  \\\n",
       "276     26  RZ034  2024-04-12  10-22-23   2  regular  rig2            0.0686   \n",
       "277      0  RZ036  2024-04-12  10-23-31   2  regular  rig3            0.0659   \n",
       "278    231  RZ037  2024-04-12  11-09-19   2  regular  rig3            0.0659   \n",
       "279    176  RZ038  2024-04-12  11-14-07   2  regular  rig2            0.0686   \n",
       "280    305  RZ039  2024-04-12  12-19-19   2  regular  rig2            0.0686   \n",
       "\n",
       "     total_trial  total_reward  avg_tw                        dir group  \\\n",
       "276          505           700    1.18  2024-04-12_10-22-23_RZ034     s   \n",
       "277          429           700    1.47  2024-04-12_10-23-31_RZ036     s   \n",
       "278          310           700    4.74  2024-04-12_11-09-19_RZ037     l   \n",
       "279          156           385    8.72  2024-04-12_11-14-07_RZ038     l   \n",
       "280          264           700    3.75  2024-04-12_12-19-19_RZ039     l   \n",
       "\n",
       "     session  \n",
       "276       55  \n",
       "277       56  \n",
       "278       55  \n",
       "279       55  \n",
       "280       55  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_all, sessions_training = generate_session_logs(data_folder)\n",
    "\n",
    "sessions_training.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct sessions log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_basics(events):\n",
    "    num_trials = events.session_trial_num.max() \n",
    "    last_trial = events.loc[events['session_trial_num'] == num_trials]\n",
    "\n",
    "    num_blocks = last_trial.loc[(last_trial['key'] == 'trial') & (last_trial['value'] == 1), 'block_num'].iloc[0] + 1\n",
    "    total_reward = round(events.reward_size.sum(), 2)\n",
    "    total_time = round((events.session_time.max() - events.session_time.min()), 2)\n",
    "    session_basics = {'num_blocks': num_blocks,\n",
    "                      'num_trials': num_trials + 1,\n",
    "                      'rewards': total_reward,\n",
    "                      'session_time': total_time}\n",
    "    return session_basics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sessions_training(data_folder, save_log=True):\n",
    "    _, sessions_training = generate_session_logs(data_folder, save_logs=False)\n",
    "    session_info_list = []\n",
    "    for _, session_info in sessions_training.iterrows():\n",
    "        events_processed = pd.read_csv(utils.generate_events_processed_path(data_folder, session_info), low_memory=False)\n",
    "        session_basics = get_session_basics(events_processed)\n",
    "        session_basics['dir'] = session_info['dir']\n",
    "        session_info_list.append(session_basics)\n",
    "    sessions_info = pd.DataFrame(session_info_list)\n",
    "    corrected_sessions_training = pd.merge(sessions_training, sessions_info, on=\"dir\")\n",
    "    corrected_sessions_training = corrected_sessions_training.drop(columns=['index', 'total_reward', 'total_trial', 'total_reward'])\n",
    "    corrected_sessions_training = corrected_sessions_training.groupby('mouse', group_keys=False).apply(helper.assign_session_numbers)\n",
    "    if save_log:\n",
    "        utils.save_as_csv(df=corrected_sessions_training, folder=data_folder, filename='sessions_training.csv')\n",
    "    return corrected_sessions_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 sessions in total\n"
     ]
    }
   ],
   "source": [
    "sessions_training = correct_sessions_training(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_basics(trial):\n",
    "    \"\"\"gets the df of a trial, extracts 5 things, and outputs as a dictionary\"\"\"\n",
    "    trial_start = trial.loc[(trial['key'] == 'trial') & (trial['value'] == 1)].iloc[0]\n",
    "    trial_end = trial.loc[(trial['key'] == 'trial') & (trial['value'] == 0)].iloc[0]\n",
    "\n",
    "    trial_basics = {'session_trial_num': trial_start['session_trial_num'],\n",
    "                    'block_trial_num': trial_start['block_trial_num'],\n",
    "                    'block_num': trial_start['block_num'],\n",
    "                    'start_time': trial_start['session_time'],\n",
    "                    'end_time': trial_end['session_time']}\n",
    "    return trial_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trials(session_info, events):\n",
    "    trial_info_list = []\n",
    "    for t in range(int(session_info.num_trials)):\n",
    "        trial = events.loc[events['session_trial_num'] == t]\n",
    "        trial_basics = get_trial_basics(trial)\n",
    "        trial_info_list.append(trial_basics)\n",
    "    trials = pd.DataFrame(trial_info_list)\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all trials based on events processed\n",
    "problematic_sessions = pd.DataFrame(columns=sessions_training.columns)\n",
    "for _, session_info in sessions_training.iterrows():\n",
    "    try: \n",
    "        trials_path = utils.generate_trials_path(data_folder, session_info)\n",
    "        if os.path.isfile(trials_path):\n",
    "            continue\n",
    "        \n",
    "        events_processed = pd.read_csv(utils.generate_events_processed_path(data_folder, session_info))\n",
    "        trials = generate_trials(session_info, events_processed)\n",
    "\n",
    "        trials.to_csv(trials_path)\n",
    "    except:\n",
    "        problematic_sessions = pd.concat([problematic_sessions, session_info.to_frame().T], ignore_index=True)\n",
    "\n",
    "if len(problematic_sessions) > 0:\n",
    "    display(problematic_sessions)\n",
    "else:\n",
    "    print(\"all sessions are perfect! woohoo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, session_info in sessions_training.iterrows():\n",
    "    try:\n",
    "        trials_analyzed_path = utils.generate_trials_analyzed_path(data_folder, session_info)\n",
    "        if os.path.isfile(trials_analyzed_path):\n",
    "            continue\n",
    "        \n",
    "        session_by_trial = utils.load_data(utils.generate_events_processed_path(data_folder, session_info)).groupby('session_trial_num')\n",
    "        trials = utils.load_data(utils.generate_trials_path(data_folder, session_info))\n",
    "        trials_data = helper.get_trial_data_df(session_by_trial)\n",
    "        trials_analyzed = pd.merge(trials, trials_data, on='session_trial_num')\n",
    "        trials_analyzed['group'] = session_info.group #assigning trial type manually\n",
    "        trials_analyzed.to_csv(trials_analyzed_path)\n",
    "    except:\n",
    "        display(session_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LUCKYCHARM",
   "language": "python",
   "name": "luckycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
