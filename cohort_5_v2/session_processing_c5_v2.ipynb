{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import session_processing_helper_c5 as helper\n",
    "import utils_c5 as utils\n",
    "\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enter cohort name and folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = '20240531_to_20240703'\n",
    "to_analyze = 'full_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rebekahzhang/data/behavior_data/20240531_to_20240703/full_clean\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/rebekahzhang/data/behavior_data'\n",
    "data_folder = os.path.join(data_dir, cohort, to_analyze)\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing files in data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all sessions have both events and meta\n"
     ]
    }
   ],
   "source": [
    "missing_count = 0\n",
    "subentry_list = []\n",
    "for entry in os.scandir(data_folder):\n",
    "  if entry.is_dir():\n",
    "    session_folder = entry.name\n",
    "    session_path = os.path.join(data_folder, session_folder)\n",
    "    \n",
    "    events_found = False\n",
    "    meta_found = False\n",
    "\n",
    "    # Check for files within the session folder (using scandir again)\n",
    "    for subentry in os.scandir(session_path):\n",
    "      if subentry.is_file():  # Check for files only\n",
    "        filename = subentry.name\n",
    "        if filename.startswith('.'):\n",
    "          continue\n",
    "        elif filename.startswith(\"events_\"):\n",
    "          events_found = True\n",
    "        elif filename.startswith(\"meta_\"):\n",
    "          meta_found = True\n",
    "\n",
    "    if not (events_found and meta_found):\n",
    "      subentry_list.append(session_folder)\n",
    "      missing_count += 1\n",
    "      print(f\"Session '{session_folder}' is missing one or both required files.\")\n",
    "    \n",
    "if missing_count>0:\n",
    "  print(f\"{missing_count} sessions have missing files\")\n",
    "  subentry_list.sort()\n",
    "  subentry_list\n",
    "else:\n",
    "  print(\"all sessions have both events and meta\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sessions log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate session log using meta data from each session and add columns of basic info to each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_total_trial(row):\n",
    "    if row['ending_code'] == 'pygame':\n",
    "        return row['total_trial'] - 1\n",
    "    elif row['ending_code'] == 'miss':\n",
    "        return row['total_trial'] - 5\n",
    "    else:\n",
    "        return row['total_trial']\n",
    "\n",
    "# changes total number of trials based on ending code. pygame leads to minus\n",
    "# currently does not account for system crashing\n",
    "sessions_all['total_trial'] = sessions_all.apply(modify_total_trial, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_sessions_all(sessions_all):\n",
    "    sessions_all[['exp', 'group']] = sessions_all['exp'].str.extract(r'exp(\\d)_(short|long)')\n",
    "    sessions_all['group'] = sessions_all['group'].map({'short': 's', 'long': 'l'})\n",
    "    sessions_all['total_trial'] = sessions_all.apply(modify_total_trial, axis=1)\n",
    "    return sessions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sessions_all(data_folder):\n",
    "    \"\"\"Generates a DataFrame using session metadata from JSON files.\n",
    "    Args:\n",
    "        data_folder (str): Path to the directory containing JSON files.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing session metadata, sorted by 'dir' column.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    for root, _, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.startswith(\"meta_\") and file.endswith(\".json\"):\n",
    "                path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(path) as f:\n",
    "                        session_data = json.load(f)['session_config']\n",
    "                        data.append(session_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    sessions_all = pd.DataFrame(data)\n",
    "    sessions_all['dir'] = sessions_all['date']+ '_' + sessions_all['time'] + '_' + sessions_all['mouse']\n",
    "    sessions_all = sessions_all.sort_values('dir')\n",
    "    sessions_all = modify_sessions_all(sessions_all)\n",
    "    return sessions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_all = generate_sessions_all(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>mouse</th>\n",
       "      <th>exp</th>\n",
       "      <th>training</th>\n",
       "      <th>rig</th>\n",
       "      <th>trainer</th>\n",
       "      <th>record</th>\n",
       "      <th>forward_file</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>total_trial</th>\n",
       "      <th>avg_tw</th>\n",
       "      <th>ending_code</th>\n",
       "      <th>dir</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>09-46-24</td>\n",
       "      <td>RZ034</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>700</td>\n",
       "      <td>417</td>\n",
       "      <td>1.60</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-05-31_09-46-24_RZ034</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>09-47-49</td>\n",
       "      <td>RZ036</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>700</td>\n",
       "      <td>423</td>\n",
       "      <td>1.58</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-05-31_09-47-49_RZ036</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>10-31-20</td>\n",
       "      <td>RZ037</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>700</td>\n",
       "      <td>472</td>\n",
       "      <td>1.60</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-05-31_10-31-20_RZ037</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>10-34-49</td>\n",
       "      <td>RZ038</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>530</td>\n",
       "      <td>273</td>\n",
       "      <td>2.57</td>\n",
       "      <td>miss</td>\n",
       "      <td>2024-05-31_10-34-49_RZ038</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>11-45-06</td>\n",
       "      <td>RZ039</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>700</td>\n",
       "      <td>386</td>\n",
       "      <td>1.92</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-05-31_11-45-06_RZ039</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>13-16-12</td>\n",
       "      <td>RZ055</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>420</td>\n",
       "      <td>175</td>\n",
       "      <td>4.29</td>\n",
       "      <td>miss</td>\n",
       "      <td>2024-07-03_13-16-12_RZ055</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>14-09-14</td>\n",
       "      <td>RZ056</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig3</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>700</td>\n",
       "      <td>356</td>\n",
       "      <td>5.15</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-07-03_14-09-14_RZ056</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>15-16-45</td>\n",
       "      <td>RZ055</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>290</td>\n",
       "      <td>93</td>\n",
       "      <td>8.08</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-07-03_15-16-45_RZ055</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>15-52-34</td>\n",
       "      <td>RZ054</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>160</td>\n",
       "      <td>84</td>\n",
       "      <td>2.62</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-07-03_15-52-34_RZ054</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>16-11-45</td>\n",
       "      <td>RZ052</td>\n",
       "      <td>2</td>\n",
       "      <td>regular</td>\n",
       "      <td>rig2</td>\n",
       "      <td>Lianne</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>106</td>\n",
       "      <td>1.23</td>\n",
       "      <td>reward</td>\n",
       "      <td>2024-07-03_16-11-45_RZ052</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      time  mouse exp training   rig trainer  record  \\\n",
       "15   2024-05-31  09-46-24  RZ034   2  regular  rig2  Lianne   False   \n",
       "102  2024-05-31  09-47-49  RZ036   2  regular  rig3  Lianne   False   \n",
       "133  2024-05-31  10-31-20  RZ037   2  regular  rig2  Lianne   False   \n",
       "126  2024-05-31  10-34-49  RZ038   2  regular  rig3  Lianne   False   \n",
       "148  2024-05-31  11-45-06  RZ039   2  regular  rig3  Lianne   False   \n",
       "..          ...       ...    ...  ..      ...   ...     ...     ...   \n",
       "61   2024-07-03  13-16-12  RZ055   2  regular  rig3  Lianne   False   \n",
       "225  2024-07-03  14-09-14  RZ056   2  regular  rig3  Lianne   False   \n",
       "238  2024-07-03  15-16-45  RZ055   2  regular  rig2  Lianne   False   \n",
       "2    2024-07-03  15-52-34  RZ054   2  regular  rig2  Lianne   False   \n",
       "235  2024-07-03  16-11-45  RZ052   2  regular  rig2  Lianne   False   \n",
       "\n",
       "     forward_file  total_reward  total_trial  avg_tw ending_code  \\\n",
       "15           True           700          417    1.60      reward   \n",
       "102          True           700          423    1.58      reward   \n",
       "133          True           700          472    1.60      reward   \n",
       "126          True           530          273    2.57        miss   \n",
       "148          True           700          386    1.92      reward   \n",
       "..            ...           ...          ...     ...         ...   \n",
       "61           True           420          175    4.29        miss   \n",
       "225          True           700          356    5.15      reward   \n",
       "238          True           290           93    8.08      reward   \n",
       "2            True           160           84    2.62      reward   \n",
       "235          True           130          106    1.23      reward   \n",
       "\n",
       "                           dir group  \n",
       "15   2024-05-31_09-46-24_RZ034     s  \n",
       "102  2024-05-31_09-47-49_RZ036     s  \n",
       "133  2024-05-31_10-31-20_RZ037     l  \n",
       "126  2024-05-31_10-34-49_RZ038     l  \n",
       "148  2024-05-31_11-45-06_RZ039     l  \n",
       "..                         ...   ...  \n",
       "61   2024-07-03_13-16-12_RZ055     l  \n",
       "225  2024-07-03_14-09-14_RZ056     l  \n",
       "238  2024-07-03_15-16-45_RZ055     l  \n",
       "2    2024-07-03_15-52-34_RZ054     l  \n",
       "235  2024-07-03_16-11-45_RZ052     l  \n",
       "\n",
       "[250 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine session quality\n",
    "doesn't need to run when data folder is cleaned \n",
    "<br>\n",
    "sessions_all needs to be regenerated after every cleaning step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove test sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sessions(sessions_to_remove, data_folder):\n",
    "    for _, session_info in sessions_to_remove.iterrows():\n",
    "        shutil.rmtree(os.path.join(data_folder, session_info.dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no test sessions\n"
     ]
    }
   ],
   "source": [
    "sessions_test = sessions_all.loc[sessions_all.mouse=='test']\n",
    "if len(sessions_test) > 0:\n",
    "    remove_sessions(sessions_test, data_folder)\n",
    "else:\n",
    "    print(\"no test sessions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for short sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no short sessions!\n"
     ]
    }
   ],
   "source": [
    "sessions_short = sessions_all.loc[sessions_all['total_trial'] < 30] \n",
    "if len(sessions_short)>0:\n",
    "    display(sessions_short)\n",
    "else: \n",
    "    print('no short sessions!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove short sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_sessions(sessions_short, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regenerate sessions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_all = generate_sessions_all(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = sessions_all.loc[sessions_all.training == 'regular'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_as_csv(df=sessions_all, folder=data_folder, filename='sessions_all.csv')\n",
    "utils.save_as_csv(df=sessions_training, folder=data_folder, filename='sessions_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code to be ignored for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for session number mismatch for each \n",
    "______________maybe i dont need to do it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dict of number or rounds for each date\n",
    "mouse_list = utils.generate_mouse_list(sessions_all)\n",
    "sessions_by_date = sessions_all.groupby('date')\n",
    "rounds_dict = {}\n",
    "for date, data in sessions_by_date:\n",
    "    num_session_list = []\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        num_session_list.append(len(mouse_by_date))\n",
    "    rounds_dict[date] = statistics.mode(num_session_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for missing sessions, copy and paste from previous day to pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing_sessions = True\n",
    "for date, data in sessions_by_date:\n",
    "    rounds = rounds_dict[date]\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        if len(mouse_by_date) < rounds:\n",
    "            no_missing_sessions = False\n",
    "            print(f\"on {date}, {mouse} has missing sessions\")\n",
    "if no_missing_sessions:\n",
    "    print(\"no missing sessions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad if missing session exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left here to examine the sessions and mice that need to be handled\n",
    "# day = sessions_by_date.get_group('2024-04-02').sort_values('mouse')\n",
    "# display(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for multiple sessions on the same day. decide if stitching is needed. stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_stitch = []\n",
    "mice_to_stitch = []\n",
    "for date, data in sessions_by_date:\n",
    "    rounds = rounds_dict[date]\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        if (len(mouse_by_date) > rounds) & (len(mouse_by_date) > 1):\n",
    "            days_to_stitch.append(date)\n",
    "            mice_to_stitch.append(mouse)\n",
    "            print(f\"on {date}, {mouse} has {len(mouse_by_date)} sessions\")\n",
    "if not days_to_stitch:\n",
    "    print(\"no sessions to stitch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it if session stitching is needed, nothing would happen otherwise\n",
    "if not days_to_stitch:\n",
    "    print(\"no sessions to stitch!\")\n",
    "else:\n",
    "    for d, m in zip(days_to_stitch, mice_to_stitch):\n",
    "        day = sessions_by_date.get_group(d)\n",
    "        sessions_to_stitch = day[day['mouse'] == m]\n",
    "\n",
    "        session_1_dir = utils.generate_events_processed_path(data_folder, sessions_to_stitch.iloc[0])\n",
    "        session_2_dir = utils.generate_events_processed_path(data_folder, sessions_to_stitch.iloc[1])\n",
    "\n",
    "        if os.path.exists(session_1_dir) and os.path.exists(session_2_dir):\n",
    "            session_1 = pd.read_csv(session_1_dir)\n",
    "            session_2 = pd.read_csv(session_2_dir)\n",
    "            stitched_session = helper.stitch_sessions(session_1, session_2) \n",
    "            #should change to stitch events. stitch sessions should be deleted. to follow nomanclature, all session should be renamed to events!!\n",
    "\n",
    "            stitched_session.to_csv(session_1_dir, index=False)\n",
    "            shutil.rmtree(os.path.join(data_folder, sessions_to_stitch.iloc[1].dir))\n",
    "            print(f\"{d} {m} session 2 deleted\")\n",
    "        else:\n",
    "            print(\"one of the sessions do not exist\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a copy of cleaned data before preceeding! and need to re generate session log!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional info to session logs and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_all = generate_sessions_all(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_basics_list = []\n",
    "for _, session_info in sessions_all.iterrows():\n",
    "    try:\n",
    "        events = pd.read_csv(utils.generate_events_path(data_folder, session_info))\n",
    "        session_basics = {'dir': session_info.dir} | helper.get_session_basics(events)\n",
    "        session_basics_list.append(session_basics)\n",
    "    except:\n",
    "        print(session_info.dir)\n",
    "session_basics_df = pd.DataFrame(session_basics_list)\n",
    "sessions_all = pd.merge(sessions_all, session_basics_df, on='dir')\n",
    "sessions_all = sessions_all.drop(['pump_ul_per_turn', 'total_trial', 'total_reward'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add number of days trained for training sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = sessions_all.loc[sessions_all.training == 'regular'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = sessions_training.groupby('mouse', group_keys=False).apply(helper.assign_session_numbers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves all sessions log and training session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_as_csv(df=sessions_all, folder=data_folder, filename='sessions_all.csv')\n",
    "utils.save_as_csv(df=sessions_training, folder=data_folder, filename='sessions_training.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process raw session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = utils.load_data(os.path.join(data_folder, 'sessions_training.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_events(session_info, events):\n",
    "    ending_to_adjust = ['pygame', 'miss']\n",
    "    ending_smooth = ['time', 'reward', 'trial']\n",
    "    if session_info['ending_code'] in ending_to_adjust:\n",
    "        events = events.loc[events['session_trial_num'].between(0, session_info['total_trial'])]\n",
    "    elif session_info['ending_code'] in ending_smooth:\n",
    "        events = events.iloc[2:-1]\n",
    "    else:\n",
    "        print(session_info['dir'])\n",
    "        raise \"ending code unknown\"\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process events by triming the beginning and the end and adding trial time\n",
    "for _, session_info in sessions_training.iterrows():\n",
    "    try:\n",
    "        events_processed_path = utils.generate_events_processed_path(data_folder, session_info)\n",
    "        if os.path.isfile(events_processed_path):\n",
    "            continue\n",
    "\n",
    "        events = pd.read_csv(utils.generate_events_path(data_folder, session_info), low_memory=False)\n",
    "        events = process_events(session_info, events)\n",
    "        events_processed = events.groupby('session_trial_num', group_keys=False).apply(helper.add_trial_time)\n",
    "        events_processed.to_csv(events_processed_path)\n",
    "    except:\n",
    "        print(session_info['dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_basics(trial):\n",
    "    \"\"\"gets the df of a trial, extracts 5 things, and outputs as a dictionary\"\"\"\n",
    "    trial_start = trial.loc[(trial['key'] == 'trial') & (trial['value'] == 1)].iloc[0]\n",
    "    trial_end = trial.loc[(trial['key'] == 'trial') & (trial['value'] == 0)].iloc[0]\n",
    "\n",
    "    trial_basics = {'session_trial_num': trial_start['session_trial_num'],\n",
    "                    'block_trial_num': trial_start['block_trial_num'],\n",
    "                    'block_num': trial_start['block_num'],\n",
    "                    'start_time': trial_start['session_time'],\n",
    "                    'end_time': trial_end['session_time']}\n",
    "    return trial_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trials(session_info, events):\n",
    "    trial_info_list = []\n",
    "    for t in range(int(session_info.total_trial)):\n",
    "        trial = events.loc[events['session_trial_num'] == t]\n",
    "        trial_basics = get_trial_basics(trial)\n",
    "        trial_info_list.append(trial_basics)\n",
    "    trials = pd.DataFrame(trial_info_list)\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all trials based on events processed\n",
    "for _, session_info in sessions_training.iterrows():\n",
    "    try: \n",
    "        trials_path = utils.generate_trials_path(data_folder, session_info)\n",
    "        if os.path.isfile(trials_path):\n",
    "            continue\n",
    "        \n",
    "        events_processed = pd.read_csv(utils.generate_events_processed_path(data_folder, session_info))\n",
    "        trials = generate_trials(session_info, events_processed)\n",
    "\n",
    "        trials.to_csv(trials_path)\n",
    "    except:\n",
    "        display(session_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, session_info in sessions_training.iterrows():\n",
    "    trials_analyzed_path = utils.generate_trials_analyzed_path(data_folder, session_info)\n",
    "    # if os.path.isfile(trials_analyzed_path):\n",
    "    #     continue\n",
    "    \n",
    "    session_by_trial = utils.load_data(utils.generate_events_processed_path(data_folder, session_info)).groupby('session_trial_num')\n",
    "    trials = utils.load_data(utils.generate_trials_path(data_folder, session_info))\n",
    "    trials_data = helper.get_trial_data_df(session_by_trial)\n",
    "    trials_analyzed = pd.merge(trials, trials_data, on='session_trial_num')\n",
    "    trials_analyzed['group'] = session_info.group #assigning trial type manually\n",
    "    trials_analyzed.to_csv(trials_analyzed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think so far it works till here. code needs to be cleaned up tho\n",
    "issues i see: 1. generate trials can use groupby? 2. code is not clean. 3. need more rules to catch data corruption. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch sessions from the same day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to run this separately for exp2 and exp3, adjust based on next exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_folder = os.path.join(data_dir, cohort, 'exp2')\n",
    "data_folder_exp2 = os.path.join(exp2_folder, 'full_clean')\n",
    "exp3_folder = os.path.join(data_dir, cohort, 'exp3')\n",
    "data_folder_exp3 = os.path.join(exp3_folder, 'full_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_folder_exp2 = os.path.join(exp2_folder, \"stitched\")\n",
    "stitched_folder_exp3 = os.path.join(exp3_folder, \"stitched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training_exp2 = utils.load_data(os.path.join(data_folder_exp2, 'sessions_training_exp2.csv'))\n",
    "sessions_training_exp3 = utils.load_data(os.path.join(data_folder_exp3, 'sessions_training_exp3.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate session with each training day as an entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stitched_all_mice_session_log(session_log):\n",
    "    stitched_session_log = session_log[['date', 'training', 'exp']].copy()\n",
    "    stitched_session_log = stitched_session_log.drop_duplicates(subset=['date'], keep='first')\n",
    "    return stitched_session_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training_stitched_exp2 = generate_stitched_all_mice_session_log(sessions_training_exp2)\n",
    "sessions_training_stitched_exp3 = generate_stitched_all_mice_session_log(sessions_training_exp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates empty directoreis in the stitched folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in sessions_training_stitched_exp2.date:\n",
    "    new_dir = os.path.join(stitched_folder_exp2, date)\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in sessions_training_stitched_exp3.date:\n",
    "    new_dir = os.path.join(stitched_folder_exp3, date)\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through each day to stitch events_processed and trials_analyzed from all mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_by_date_exp2 = sessions_training_exp2.groupby('date')\n",
    "sessions_by_date_exp3 = sessions_training_exp3.groupby('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trials_analyzed_stitched_path(data_folder, session_info):\n",
    "    filename = f'trials_analyzed_stitched_{session_info.date}.csv'\n",
    "    return os.path.join(data_folder, session_info.date, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_events_processed_stitched_path(data_folder, session_info):\n",
    "    filename = f'events_processed_stitched_{session_info.date}.csv'\n",
    "    return os.path.join(data_folder, f\"{session_info.date}\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_events(events_1, events_2):\n",
    "    session_1_basics = helper.get_session_basics(events_1)\n",
    "    time_offset = session_1_basics['session_time']\n",
    "    block_offset = session_1_basics['num_blocks']\n",
    "    trial_offset = session_1_basics['num_trials']\n",
    "    \n",
    "    events_2.session_time = events_2.session_time + time_offset\n",
    "    events_2.block_num = events_2.block_num + block_offset\n",
    "    events_2.session_trial_num= events_2.session_trial_num + trial_offset\n",
    "\n",
    "    stitched_session = pd.concat([events_1, events_2])\n",
    "    return stitched_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_trials(trials_1, trials_2):\n",
    "    trial_offset = trials_1.session_trial_num.max()+1\n",
    "    block_offset = trials_1.block_num.max()+1\n",
    "    time_offset = trials_1.end_time.max()\n",
    "    \n",
    "    trials_2.session_trial_num = trials_2.session_trial_num + trial_offset\n",
    "    trials_2.block_num = trials_2.block_num + block_offset\n",
    "    trials_2.start_time = trials_2.start_time + time_offset\n",
    "    trials_2.end_time = trials_2.end_time + time_offset\n",
    "\n",
    "    stitched_all_trials = pd.concat([trials_1, trials_2])\n",
    "    return stitched_all_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this between reruns to prevent the df \n",
    "events_stitched = None\n",
    "trials_stitched = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUG HERE!!! MOUSE NAME NOT PRESERVED!!!! FIX IT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, date in sessions_by_date_exp2:\n",
    "    num_mice = len(date)\n",
    "    session_info = date.iloc[0]\n",
    "    events_stitched = utils.load_data(utils.generate_events_processed_path(data_folder, session_info))\n",
    "    events_stitched['mouse'] = session_info['mouse']\n",
    "    trials_stitched = utils.load_data(utils.generate_trials_analyzed_path(data_folder, session_info))\n",
    "    trials_stitched['mouse'] = session_info['mouse']\n",
    "\n",
    "    for i in range(1, num_mice):\n",
    "        events_2 = utils.load_data(utils.generate_events_processed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        trials_2 = utils.load_data(utils.generate_trials_analyzed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        events_stitched = stitch_events(events_stitched, events_2)\n",
    "        trials_stitched = stitch_trials(trials_stitched, trials_2)\n",
    "    \n",
    "    events_stitched.to_csv(generate_events_processed_stitched_path(stitched_folder_exp2, session_info), index=False)\n",
    "    trials_stitched.to_csv(generate_trials_analyzed_stitched_path(stitched_folder_exp2, session_info), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, date in sessions_by_date_exp3:\n",
    "    num_mice = len(date)\n",
    "    session_info = date.iloc[0]\n",
    "    events_stitched = utils.load_data(utils.generate_events_processed_path(data_folder, session_info))\n",
    "    events_stitched['mouse'] = session_info['mouse']\n",
    "    trials_stitched = utils.load_data(utils.generate_trials_analyzed_path(data_folder, session_info))\n",
    "    trials_stitched['mouse'] = session_info['mouse']\n",
    "\n",
    "    for i in range(1, num_mice):\n",
    "        events_2 = utils.load_data(utils.generate_events_processed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        trials_2 = utils.load_data(utils.generate_trials_analyzed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        events_stitched = stitch_events(events_stitched, events_2)\n",
    "        trials_stitched = stitch_trials(trials_stitched, trials_2)\n",
    "    \n",
    "    events_stitched.to_csv(generate_events_processed_stitched_path(stitched_folder_exp3, session_info), index=False)\n",
    "    trials_stitched.to_csv(generate_trials_analyzed_stitched_path(stitched_folder_exp3, session_info), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add info to stitched session log and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_session_basics_list = []\n",
    "for _, session_info in sessions_training_stitched_exp2.iterrows():\n",
    "    events = pd.read_csv(generate_events_processed_stitched_path(stitched_folder_exp2, session_info))\n",
    "    session_basics = {'date': session_info.date} | helper.get_session_basics(events)\n",
    "    stitched_session_basics_list.append(session_basics)\n",
    "stitched_session_basics = pd.DataFrame(stitched_session_basics_list)\n",
    "stitched_session_log_2 = pd.merge(sessions_training_stitched_exp2, stitched_session_basics, on='date')\n",
    "utils.save_as_csv(df=stitched_session_log_2, folder=stitched_folder_exp2, filename='sessions_training_stitched_exp2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_session_basics_list = []\n",
    "for _, session_info in sessions_training_stitched_exp3.iterrows():\n",
    "    events = pd.read_csv(generate_events_processed_stitched_path(stitched_folder_exp3, session_info))\n",
    "    session_basics = {'date': session_info.date} | helper.get_session_basics(events)\n",
    "    stitched_session_basics_list.append(session_basics)\n",
    "stitched_session_basics = pd.DataFrame(stitched_session_basics_list)\n",
    "stitched_session_log_3 = pd.merge(sessions_training_stitched_exp3, stitched_session_basics, on='date')\n",
    "utils.save_as_csv(df=stitched_session_log_3, folder=stitched_folder_exp3, filename='sessions_training_stitched_exp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LUCKYCHARM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
