{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import session_processing_helper_c5 as helper\n",
    "import utils_c5 as utils\n",
    "\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enter cohort name and folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = 'cohort_5'\n",
    "to_analyze = 'full_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rebekahzhang/data/behavior_data/cohort_5/full_clean\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/rebekahzhang/data/behavior_data'\n",
    "data_folder = os.path.join(data_dir, cohort, to_analyze)\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code cannot handel stitching if the first session didn't end properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ideally, session processing can just happen as part of the pi code, so process raw sessions to align trial num and trial state doesnt need to happen. pi code should also add in exit code. so when max missed trial happens, then those trials can be cut out. and if improper end happens, those trials can also be cut out.\n",
    "<br>\n",
    "the ideal work flow is to have the following:\n",
    "<br>\n",
    " - write file folder, and initite path generator class, and load all helper functions\n",
    " - examine the quality of sessions: delete test and short sessions\n",
    " - trim beginning and end of events\n",
    " - pad or stitch if there is a mis match of session numbers\n",
    " - generate trials based on event info\n",
    " - analyze trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sessions log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate session log using meta data from each session and add columns of basic info to each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sessions_all(data_folder):\n",
    "    sessions_all = pd.DataFrame()\n",
    "    for root, _, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.startswith(\"meta_\") and file.endswith(\".json\"):\n",
    "                path = os.path.join(root, file)\n",
    "                with open(path) as f:\n",
    "                    session_data = json.load(f)\n",
    "                session_meta = pd.DataFrame([session_data])  # Wrap in a list to create a single-row DataFrame\n",
    "                sessions_all = pd.concat([sessions_all, session_meta], ignore_index=True)\n",
    "                \n",
    "    if not sessions_all.empty:\n",
    "        sessions_all['dir'] = sessions_all['date']+ '_' + sessions_all['time'] + '_' + sessions_all['mouse']\n",
    "        sessions_all[['exp', 'group']] = sessions_all['exp'].str.extract(r'exp(\\d)_(short|long)')\n",
    "        sessions_all['group'] = sessions_all['group'].map({'short': 's', 'long': 'l'})\n",
    "    sessions_all=sessions_all.sort_values('dir')\n",
    "    return sessions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_all = generate_sessions_all(data_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine session quality\n",
    "doesn't need to run when data folder is cleaned \n",
    "<br>\n",
    "sessions_all needs to be regenerated after every cleaning step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove test sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sessions(sessions_to_remove, data_folder):\n",
    "    for _, session_info in sessions_to_remove.iterrows():\n",
    "        shutil.rmtree(os.path.join(data_folder, session_info.dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no test sessions\n"
     ]
    }
   ],
   "source": [
    "sessions_test = sessions_all.loc[sessions_all.mouse=='test']\n",
    "if len(sessions_test) > 0:\n",
    "    remove_sessions(sessions_test, data_folder)\n",
    "else:\n",
    "    print(\"no test sessions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for short sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no short sessions!\n"
     ]
    }
   ],
   "source": [
    "sessions_short = sessions_all.loc[sessions_all['total_trial'] < 50] \n",
    "if len(sessions_short)>0:\n",
    "    display(sessions_short)\n",
    "else: \n",
    "    print('no short sessions!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove short sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_sessions(sessions_short, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regenerate sessions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_all = generate_sessions_all(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for session number mismatch for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dict of number or rounds for each date\n",
    "mouse_list = utils.generate_mouse_list(sessions_all)\n",
    "sessions_by_date = sessions_all.groupby('date')\n",
    "rounds_dict = {}\n",
    "for date, data in sessions_by_date:\n",
    "    num_session_list = []\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        num_session_list.append(len(mouse_by_date))\n",
    "    rounds_dict[date] = statistics.mode(num_session_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for missing sessions, copy and paste from previous day to pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 2024-01-24, RZ045 has missing sessions\n",
      "on 2024-03-31, RZ034 has missing sessions\n",
      "on 2024-03-31, RZ036 has missing sessions\n",
      "on 2024-03-31, RZ037 has missing sessions\n",
      "on 2024-03-31, RZ038 has missing sessions\n",
      "on 2024-03-31, RZ039 has missing sessions\n"
     ]
    }
   ],
   "source": [
    "no_missing_sessions = True\n",
    "for date, data in sessions_by_date:\n",
    "    rounds = rounds_dict[date]\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        if len(mouse_by_date) < rounds:\n",
    "            no_missing_sessions = False\n",
    "            print(f\"on {date}, {mouse} has missing sessions\")\n",
    "if no_missing_sessions:\n",
    "    print(\"no missing sessions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad if missing session exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left here to examine the sessions and mice that need to be handled\n",
    "# day = sessions_by_date.get_group('2024-04-02').sort_values('mouse')\n",
    "# display(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for multiple sessions on the same day. decide if stitching is needed. stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 2024-04-15, RZ038 has 2 sessions\n"
     ]
    }
   ],
   "source": [
    "days_to_stitch = []\n",
    "mice_to_stitch = []\n",
    "for date, data in sessions_by_date:\n",
    "    rounds = rounds_dict[date]\n",
    "    for mouse in mouse_list:\n",
    "        mouse_by_date = data.loc[data['mouse'] == mouse]\n",
    "        if (len(mouse_by_date) > rounds) & (len(mouse_by_date) > 1):\n",
    "            days_to_stitch.append(date)\n",
    "            mice_to_stitch.append(mouse)\n",
    "            print(f\"on {date}, {mouse} has {len(mouse_by_date)} sessions\")\n",
    "if not days_to_stitch:\n",
    "    print(\"no sessions to stitch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 RZ038 session 2 deleted\n"
     ]
    }
   ],
   "source": [
    "# run it if session stitching is needed, nothing would happen otherwise\n",
    "if not days_to_stitch:\n",
    "    print(\"no sessions to stitch!\")\n",
    "else:\n",
    "    for d, m in zip(days_to_stitch, mice_to_stitch):\n",
    "        day = sessions_by_date.get_group(d)\n",
    "        sessions_to_stitch = day[day['mouse'] == m]\n",
    "\n",
    "        session_1_dir = utils.generate_events_processed_path(data_folder, sessions_to_stitch.iloc[0])\n",
    "        session_2_dir = utils.generate_events_processed_path(data_folder, sessions_to_stitch.iloc[1])\n",
    "\n",
    "        if os.path.exists(session_1_dir) and os.path.exists(session_2_dir):\n",
    "            session_1 = pd.read_csv(session_1_dir)\n",
    "            session_2 = pd.read_csv(session_2_dir)\n",
    "            stitched_session = helper.stitch_sessions(session_1, session_2) \n",
    "            #should change to stitch events. stitch sessions should be deleted. to follow nomanclature, all session should be renamed to events!!\n",
    "\n",
    "            stitched_session.to_csv(session_1_dir, index=False)\n",
    "            shutil.rmtree(os.path.join(data_folder, sessions_to_stitch.iloc[1].dir))\n",
    "            print(f\"{d} {m} session 2 deleted\")\n",
    "        else:\n",
    "            print(\"one of the sessions do not exist\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a copy of cleaned data before preceeding! and need to re generate session log!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional info to session logs and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_all = generate_sessions_all(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_basics_list = []\n",
    "for _, session_info in sessions_all.iterrows():\n",
    "    try:\n",
    "        events = pd.read_csv(utils.generate_events_path(data_folder, session_info))\n",
    "        session_basics = {'dir': session_info.dir} | helper.get_session_basics(events)\n",
    "        session_basics_list.append(session_basics)\n",
    "    except:\n",
    "        print(session_info.dir)\n",
    "session_basics_df = pd.DataFrame(session_basics_list)\n",
    "sessions_all = pd.merge(sessions_all, session_basics_df, on='dir')\n",
    "sessions_all = sessions_all.drop(['pump_ul_per_turn', 'total_trial', 'total_reward'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add number of days trained for training sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = sessions_all.loc[sessions_all.training == 'regular'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = sessions_training.groupby('mouse', group_keys=False).apply(helper.assign_session_numbers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves all sessions log and training session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_as_csv(df=sessions_all, folder=data_folder, filename='sessions_all.csv')\n",
    "utils.save_as_csv(df=sessions_training, folder=data_folder, filename='sessions_training.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process raw session and generate all_trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training = utils.load_data(os.path.join(data_folder, 'sessions_training.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate all trials, align trial number, trial state, and trial time for raw session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, session_info in sessions_training.iterrows():\n",
    "    try: \n",
    "        events_processed_path = utils.generate_events_processed_path(data_folder, session_info)\n",
    "        trials_path = utils.generate_trials_path(data_folder, session_info)\n",
    "        # if os.path.isfile(events_processed_path) and os.path.isfile(trials_path):\n",
    "        #     continue\n",
    "        \n",
    "        events = pd.read_csv(utils.generate_events_path(data_folder, session_info))\n",
    "        trials = helper.generate_trials(session_info, events)\n",
    "\n",
    "        # align trial number\n",
    "        events = helper.align_trial_number(events, trials)\n",
    "        \n",
    "        events = utils.trim_session(session_info, events)\n",
    "\n",
    "        # align trial state\n",
    "        events = events.groupby('session_trial_num', group_keys=False).apply(helper.align_trial_states)\n",
    "        # add trial_time\n",
    "        events = events.groupby('session_trial_num', group_keys=False).apply(helper.add_trial_time)\n",
    "\n",
    "        events.to_csv(events_processed_path)\n",
    "        trials.to_csv(trials_path)\n",
    "    except:\n",
    "        display(session_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, session_info in sessions_training.iterrows():\n",
    "    trials_analyzed_path = utils.generate_trials_analyzed_path(data_folder, session_info)\n",
    "    # if os.path.isfile(trials_analyzed_path):\n",
    "    #     continue\n",
    "    \n",
    "    session_by_trial = utils.load_data(utils.generate_events_processed_path(data_folder, session_info)).groupby('session_trial_num')\n",
    "    trials = utils.load_data(utils.generate_trials_path(data_folder, session_info))\n",
    "    trials_data = helper.get_trial_data_df(session_by_trial)\n",
    "    trials_analyzed = pd.merge(trials, trials_data, on='session_trial_num')\n",
    "    trials_analyzed['group'] = session_info.group #assigning trial type manually\n",
    "    trials_analyzed.to_csv(trials_analyzed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort sessions by experiment\n",
    "move exp2 session folders to exp2 folder, and same for exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_folder = os.path.join(data_dir, cohort, 'exp2')\n",
    "exp3_folder = os.path.join(data_dir, cohort, 'exp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_all = utils.load_data(os.path.join(data_folder, 'sessions_all.csv'))\n",
    "sessions_training = utils.load_data(os.path.join(data_folder, 'sessions_training.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dir_to_new_folder(session_log, data_folder, target_folder):\n",
    "    for _, session_info in session_log.iterrows():\n",
    "        session_dir = os.path.join(data_folder, session_info.dir)\n",
    "        dest_dir = os.path.join(target_folder, session_info.dir)\n",
    "\n",
    "        if os.path.exists(dest_dir):\n",
    "            continue\n",
    "        elif os.path.exists(session_dir):\n",
    "            shutil.copytree(session_dir, dest_dir)\n",
    "        else:\n",
    "            print(f\"didn't work for: {session_info.dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out logs for exp2\n",
    "sessions_all_exp2 = sessions_all.loc[sessions_all.exp == 2]\n",
    "sessions_training_exp2 = sessions_training.loc[sessions_training.exp == 2]\n",
    "# specify exp2 folder\n",
    "data_folder_exp2 = os.path.join(exp2_folder, 'full_clean')\n",
    "# move files from full_clean to exp folder\n",
    "move_dir_to_new_folder(sessions_all_exp2, data_folder, data_folder_exp2)\n",
    "# save sliced logs to exp_folde\n",
    "utils.save_as_csv(df=sessions_all_exp2, folder=data_folder_exp2, filename='sessions_all_exp2.csv')\n",
    "utils.save_as_csv(df=sessions_training_exp2, folder=data_folder_exp2, filename='sessions_training_exp2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out logs for exp3\n",
    "sessions_all_exp3 = sessions_all.loc[sessions_all.exp == 3]\n",
    "sessions_training_exp3 = sessions_training.loc[sessions_training.exp == 3]\n",
    "# specify exp3 folder\n",
    "data_folder_exp3 = os.path.join(exp3_folder, 'full_clean')\n",
    "# move files from full_clean to exp folder\n",
    "move_dir_to_new_folder(sessions_all_exp3, data_folder, data_folder_exp3)\n",
    "# save sliced logs to exp_folder\n",
    "utils.save_as_csv(df=sessions_all_exp3, folder=data_folder_exp3, filename='sessions_all_exp3.csv')\n",
    "utils.save_as_csv(df=sessions_training_exp3, folder=data_folder_exp3, filename='sessions_training_exp3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch sessions from the same day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to run this separately for exp2 and exp3, adjust based on next exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_folder = os.path.join(data_dir, cohort, 'exp2')\n",
    "data_folder_exp2 = os.path.join(exp2_folder, 'full_clean')\n",
    "exp3_folder = os.path.join(data_dir, cohort, 'exp3')\n",
    "data_folder_exp3 = os.path.join(exp3_folder, 'full_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_folder_exp2 = os.path.join(exp2_folder, \"stitched\")\n",
    "stitched_folder_exp3 = os.path.join(exp3_folder, \"stitched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load session log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training_exp2 = utils.load_data(os.path.join(data_folder_exp2, 'sessions_training_exp2.csv'))\n",
    "sessions_training_exp3 = utils.load_data(os.path.join(data_folder_exp3, 'sessions_training_exp3.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate session with each training day as an entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stitched_all_mice_session_log(session_log):\n",
    "    stitched_session_log = session_log[['date', 'training', 'exp']].copy()\n",
    "    stitched_session_log = stitched_session_log.drop_duplicates(subset=['date'], keep='first')\n",
    "    return stitched_session_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_training_stitched_exp2 = generate_stitched_all_mice_session_log(sessions_training_exp2)\n",
    "sessions_training_stitched_exp3 = generate_stitched_all_mice_session_log(sessions_training_exp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates empty directoreis in the stitched folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in sessions_training_stitched_exp2.date:\n",
    "    new_dir = os.path.join(stitched_folder_exp2, date)\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in sessions_training_stitched_exp3.date:\n",
    "    new_dir = os.path.join(stitched_folder_exp3, date)\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through each day to stitch events_processed and trials_analyzed from all mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_by_date_exp2 = sessions_training_exp2.groupby('date')\n",
    "sessions_by_date_exp3 = sessions_training_exp3.groupby('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trials_analyzed_stitched_path(data_folder, session_info):\n",
    "    filename = f'trials_analyzed_stitched_{session_info.date}.csv'\n",
    "    return os.path.join(data_folder, session_info.date, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_events_processed_stitched_path(data_folder, session_info):\n",
    "    filename = f'events_processed_stitched_{session_info.date}.csv'\n",
    "    return os.path.join(data_folder, f\"{session_info.date}\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_events(events_1, events_2):\n",
    "    session_1_basics = helper.get_session_basics(events_1)\n",
    "    time_offset = session_1_basics['session_time']\n",
    "    block_offset = session_1_basics['num_blocks']\n",
    "    trial_offset = session_1_basics['num_trials']\n",
    "    \n",
    "    events_2.session_time = events_2.session_time + time_offset\n",
    "    events_2.block_num = events_2.block_num + block_offset\n",
    "    events_2.session_trial_num= events_2.session_trial_num + trial_offset\n",
    "\n",
    "    stitched_session = pd.concat([events_1, events_2])\n",
    "    return stitched_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_trials(trials_1, trials_2):\n",
    "    trial_offset = trials_1.session_trial_num.max()+1\n",
    "    block_offset = trials_1.block_num.max()+1\n",
    "    time_offset = trials_1.end_time.max()\n",
    "    \n",
    "    trials_2.session_trial_num = trials_2.session_trial_num + trial_offset\n",
    "    trials_2.block_num = trials_2.block_num + block_offset\n",
    "    trials_2.start_time = trials_2.start_time + time_offset\n",
    "    trials_2.end_time = trials_2.end_time + time_offset\n",
    "\n",
    "    stitched_all_trials = pd.concat([trials_1, trials_2])\n",
    "    return stitched_all_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this between reruns to prevent the df \n",
    "events_stitched = None\n",
    "trials_stitched = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUG HERE!!! MOUSE NAME NOT PRESERVED!!!! FIX IT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, date in sessions_by_date_exp2:\n",
    "    num_mice = len(date)\n",
    "    session_info = date.iloc[0]\n",
    "    events_stitched = utils.load_data(utils.generate_events_processed_path(data_folder, session_info))\n",
    "    events_stitched['mouse'] = session_info['mouse']\n",
    "    trials_stitched = utils.load_data(utils.generate_trials_analyzed_path(data_folder, session_info))\n",
    "    trials_stitched['mouse'] = session_info['mouse']\n",
    "\n",
    "    for i in range(1, num_mice):\n",
    "        events_2 = utils.load_data(utils.generate_events_processed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        trials_2 = utils.load_data(utils.generate_trials_analyzed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        events_stitched = stitch_events(events_stitched, events_2)\n",
    "        trials_stitched = stitch_trials(trials_stitched, trials_2)\n",
    "    \n",
    "    events_stitched.to_csv(generate_events_processed_stitched_path(stitched_folder_exp2, session_info), index=False)\n",
    "    trials_stitched.to_csv(generate_trials_analyzed_stitched_path(stitched_folder_exp2, session_info), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, date in sessions_by_date_exp3:\n",
    "    num_mice = len(date)\n",
    "    session_info = date.iloc[0]\n",
    "    events_stitched = utils.load_data(utils.generate_events_processed_path(data_folder, session_info))\n",
    "    events_stitched['mouse'] = session_info['mouse']\n",
    "    trials_stitched = utils.load_data(utils.generate_trials_analyzed_path(data_folder, session_info))\n",
    "    trials_stitched['mouse'] = session_info['mouse']\n",
    "\n",
    "    for i in range(1, num_mice):\n",
    "        events_2 = utils.load_data(utils.generate_events_processed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        trials_2 = utils.load_data(utils.generate_trials_analyzed_path(data_folder, date.iloc[i]))\n",
    "        events_2['mouse'] = session_info['mouse']\n",
    "        events_stitched = stitch_events(events_stitched, events_2)\n",
    "        trials_stitched = stitch_trials(trials_stitched, trials_2)\n",
    "    \n",
    "    events_stitched.to_csv(generate_events_processed_stitched_path(stitched_folder_exp3, session_info), index=False)\n",
    "    trials_stitched.to_csv(generate_trials_analyzed_stitched_path(stitched_folder_exp3, session_info), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add info to stitched session log and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_session_basics_list = []\n",
    "for _, session_info in sessions_training_stitched_exp2.iterrows():\n",
    "    events = pd.read_csv(generate_events_processed_stitched_path(stitched_folder_exp2, session_info))\n",
    "    session_basics = {'date': session_info.date} | helper.get_session_basics(events)\n",
    "    stitched_session_basics_list.append(session_basics)\n",
    "stitched_session_basics = pd.DataFrame(stitched_session_basics_list)\n",
    "stitched_session_log_2 = pd.merge(sessions_training_stitched_exp2, stitched_session_basics, on='date')\n",
    "utils.save_as_csv(df=stitched_session_log_2, folder=stitched_folder_exp2, filename='sessions_training_stitched_exp2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_session_basics_list = []\n",
    "for _, session_info in sessions_training_stitched_exp3.iterrows():\n",
    "    events = pd.read_csv(generate_events_processed_stitched_path(stitched_folder_exp3, session_info))\n",
    "    session_basics = {'date': session_info.date} | helper.get_session_basics(events)\n",
    "    stitched_session_basics_list.append(session_basics)\n",
    "stitched_session_basics = pd.DataFrame(stitched_session_basics_list)\n",
    "stitched_session_log_3 = pd.merge(sessions_training_stitched_exp3, stitched_session_basics, on='date')\n",
    "utils.save_as_csv(df=stitched_session_log_3, folder=stitched_folder_exp3, filename='sessions_training_stitched_exp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LUCKYCHARM",
   "language": "python",
   "name": "luckycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
