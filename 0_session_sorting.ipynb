{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp_cohort_info.json', 'r') as f:\n",
    "    training_info = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sorting\n",
    "needed only when multiple exps and cohorts are trained during the same period of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a folder with the time period as name (eg. '20250531-20240806')\n",
    "<br>\n",
    "create a folder named raw inside the period folder and put all session files into the raw folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rebekahzhang/data/behavior_data/post_meta_change\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/rebekahzhang/data/behavior_data'\n",
    "period = 'post_meta_change'\n",
    "data_folder = os.path.join(data_dir, period)\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back up raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_copy already exist\n"
     ]
    }
   ],
   "source": [
    "raw_folder = os.path.join(data_folder, \"raw\")\n",
    "utils.backup(raw_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort sessions based on exp\n",
    "move sessions from raw folder to corresponding exp folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict = training_info['experiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_folder = os.path.join(data_folder, 'exp2')\n",
    "exp3_folder = os.path.join(data_folder, 'exp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sessions_to_exp_folders(source_path, exp2_folder, exp3_folder):\n",
    "    # Create experiment folders\n",
    "    os.makedirs(exp2_folder, exist_ok=True)\n",
    "    os.makedirs(exp3_folder, exist_ok=True)\n",
    "\n",
    "    # Create a dictionary mapping experiment names to their folder paths\n",
    "    exp_folders = {\n",
    "        \"exp2\": exp2_folder,\n",
    "        \"exp3\": exp3_folder\n",
    "    }\n",
    "\n",
    "    # Iterate through all items in the source directory\n",
    "    for item in os.listdir(source_path):\n",
    "        item_path = os.path.join(source_path, item)\n",
    "        \n",
    "        # Check if the item is a directory and matches the session folder naming pattern\n",
    "        if os.path.isdir(item_path) and len(item.split('_')) == 3:\n",
    "            date, time, mouse_name = item.split('_')\n",
    "            \n",
    "            # Find the corresponding experiment for the mouse\n",
    "            for exp, mice in exp_dict.items():\n",
    "                if mouse_name in mice:\n",
    "                    # Construct the destination path\n",
    "                    dest_path = os.path.join(exp_folders[exp], item)\n",
    "                    \n",
    "                    # Move the folder\n",
    "                    shutil.move(item_path, dest_path)\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No matching experiment found for {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching experiment found for 2025-02-12_13-18-09_test\n",
      "No matching experiment found for 2024-10-03_12-14-32_test\n",
      "No matching experiment found for 2025-03-20_16-31-58_test\n",
      "No matching experiment found for 2024-11-10_12-28-45_test\n",
      "No matching experiment found for 2025-02-21_14-27-29_test\n",
      "No matching experiment found for 2024-11-10_12-31-09_test\n",
      "No matching experiment found for 2024-09-18_12-53-03_test\n",
      "No matching experiment found for 2024-11-10_12-59-03_test\n",
      "No matching experiment found for 2025-02-12_13-16-57_test\n",
      "No matching experiment found for 2025-02-21_14-20-20_test\n",
      "No matching experiment found for 2024-10-10_16-53-31_test\n",
      "No matching experiment found for 2024-05-14_15-29-19_test\n",
      "No matching experiment found for 2025-02-21_14-14-50_test\n",
      "No matching experiment found for 2024-09-13_15-00-08_test\n",
      "No matching experiment found for 2024-05-24_16-59-10_test\n",
      "No matching experiment found for 2024-09-26_11-05-17_test\n",
      "No matching experiment found for 2024-11-10_12-04-04_test\n",
      "No matching experiment found for 2024-05-24_15-44-50_test\n",
      "No matching experiment found for 2024-09-13_14-57-17_test\n",
      "No matching experiment found for 2025-02-21_14-27-34_test\n",
      "No matching experiment found for 2024-11-10_12-43-42_test\n",
      "No matching experiment found for 2024-11-10_13-00-55_test\n",
      "No matching experiment found for 2024-09-13_13-58-23_test\n",
      "No matching experiment found for 2024-09-18_12-52-04_test\n",
      "No matching experiment found for 2024-09-26_11-03-29_test\n",
      "No matching experiment found for 2024-11-10_12-40-48_test\n",
      "No matching experiment found for 2024-11-10_12-45-33_test\n",
      "No matching experiment found for 2024-11-10_12-09-53_test\n",
      "No matching experiment found for 2024-11-10_12-26-28_test\n",
      "No matching experiment found for 2024-10-10_11-03-26_test\n",
      "No matching experiment found for 2025-02-21_14-43-48_test\n",
      "No matching experiment found for 2025-02-21_14-20-53_test\n",
      "No matching experiment found for 2024-09-13_13-55-39_test\n",
      "No matching experiment found for 2024-11-10_11-55-20_test\n",
      "No matching experiment found for 2024-10-22_10-29-58_test\n",
      "No matching experiment found for 2024-05-10_12-07-10_test\n",
      "No matching experiment found for 2025-02-21_14-26-30_test\n",
      "No matching experiment found for 2025-02-21_14-15-29_test\n",
      "No matching experiment found for 2025-02-21_14-44-26_test\n",
      "No matching experiment found for 2025-02-21_14-25-16_test\n",
      "No matching experiment found for 2025-02-21_14-33-12_test\n",
      "No matching experiment found for 2024-10-22_10-24-20_test\n",
      "No matching experiment found for 2025-02-21_14-26-46_test\n",
      "No matching experiment found for 2024-10-10_11-04-32_test\n",
      "No matching experiment found for 2025-02-21_14-33-49_test\n",
      "No matching experiment found for 2024-10-03_12-15-06_test\n",
      "No matching experiment found for 2024-11-10_12-06-26_test\n"
     ]
    }
   ],
   "source": [
    "move_sessions_to_exp_folders(raw_folder, exp2_folder, exp3_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort sessions based on cohort\n",
    "move sessions from raw folder to corresponding exp folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_dict = training_info[\"cohorts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_sessions_to_cohort_folders(exp_folder):\n",
    "    # Create cohort folders inside exp2 folder\n",
    "    for cohort in cohort_dict.keys():\n",
    "        cohort_folder = os.path.join(exp_folder, cohort)\n",
    "        os.makedirs(cohort_folder, exist_ok=True)\n",
    "    \n",
    "    for item in os.listdir(exp_folder):\n",
    "        item_path = os.path.join(exp_folder, item)\n",
    "        \n",
    "        if os.path.isdir(item_path) and len(item.split('_')) == 3:\n",
    "            _, _, mouse_name = item.split('_')\n",
    "            \n",
    "            for cohort, mice in cohort_dict.items():\n",
    "                if mouse_name in mice:\n",
    "                    dest_path = os.path.join(exp_folder, cohort, item)\n",
    "                    shutil.move(item_path, dest_path)\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No matching cohort found for {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching cohort found for cohort_8_copy\n"
     ]
    }
   ],
   "source": [
    "moving_sessions_to_cohort_folders(exp2_folder)\n",
    "moving_sessions_to_cohort_folders(exp3_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back up both folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp2_copy already exist\n",
      "exp3_copy already exist\n"
     ]
    }
   ],
   "source": [
    "utils.backup(exp2_folder)\n",
    "utils.backup(exp3_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LUCKYCHARM",
   "language": "python",
   "name": "luckycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
